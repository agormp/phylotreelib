# Project support notes for phylotreelib
20211110074114

## Ideas for coding

https://jakevdp.github.io/PythonDataScienceHandbook/02.03-computation-on-arrays-ufuncs.html

### Add numpy vector to all rows and columns of matrix (adding udist to dmat)

x = np.arange(1, 6)
y = np.add.outer(x,x)
z = np.ones((5,5))
np.add(x,z, out=z)

But after testing speed, the below is better:

    a = np.ones((5,5))
    v = np.arange(1, 6)
    vcol = v.reshape(5,1)
    a += v
    a += vcol

### Find row and column index for minimum entry in njdist ignoring diagonal

a = np.random.rand(5,5)
b = a + a.T  (make symmetric)
np.fill_diagonal(b, np.inf)
np.unravel_index(b.argmin(), b.shape)   Finds one minimal entry

### Sum dmat along axis to get udist (udist = sum of all pairwise dists to other entries)

k = np.sum(z, axis=1)

### Updating dmat during algorithm when merging nodes

Idea: 

(Perhaps: Lower triangular matrix full of np.Inf)

When merging nodes i and j:
* Fill row and column j with np.Inf
* Compute distance from new merged node to all other nodes, place in row and column i

This way dmat never changes size and no new allocation needed? 
(Perhaps use copy first round, and then in-place in that so self.dmat is unchanged)

Question: will presence of Inf cause trouble for my other algorithmic steps? eg computing udist vector can no longer adding udist vector to

## Efficiency

### Numpy arrays: multiplication in-place

    setup = "import numpy as np; a = np.random.rand(200,200)"
    stmt1 = "b = 2 * a"
    stmt2 = "a = 2 * a"
    stmt3 = "a *= 2"
    stmt4 = "a = np.multiply(a,2)"
    stmt5 = "np.multiply(a,2, out=a)"
    
    min(timeit.repeat(stmt1, setup, number=100000)):              1.215
    min(timeit.repeat(stmt2, setup, number=100000)):              1.237
    min(timeit.repeat(stmt3, setup, number=100000, repeat=10)):   0.792
    min(timeit.repeat(stmt4, setup, number=100000)):              1.205
    min(timeit.repeat(stmt5, setup, number=100000, repeat=10)):   0.778

So: `*=` seems very efficient, as is `np.multiply(a,2, out=a)`(30% - 40% faster)

### Numpy arrays: addition in place

    setup = "import numpy as np; a = np.random.rand(200,200); b = np.random.rand(200,200)"
    stmt1 = "c = a + b"
    stmt2 = "a = a + b"
    stmt3 = "a += b"
    stmt4 = "a = np.add(a,b)"
    stmt5 = "np.add(a,b, out=a)"

    min(timeit.repeat(stmt1, setup, number=100000, repeat=10)):   1.662
    min(timeit.repeat(stmt2, setup, number=100000, repeat=10)):   1.537
    min(timeit.repeat(stmt3, setup, number=100000, repeat=10)):   1.323
    min(timeit.repeat(stmt4, setup, number=100000, repeat=10)):   1.670
    min(timeit.repeat(stmt5, setup, number=100000, repeat=10)):   1.349

So: `+=` and `np.add(a,b, out=a)` again seems most efficient (about 20% faster)

### Numpy: intermediate results

    setup = "import numpy as np; a = np.random.rand(200,200); b = np.random.rand(200,200)"
    stmt1 = "c = 2*a + b"
    stmt2 = "a = 2*a + b"
    stmt3 = "a*= 2; a += b"
    stmt4 = "np.multiply(a,2, out=a); np.add(a,b, out=a)"
    
    min(timeit.repeat(stmt1, setup, number=10000, repeat=10)):  0.251
    min(timeit.repeat(stmt2, setup, number=10000, repeat=10)):  0.245
    min(timeit.repeat(stmt3, setup, number=10000, repeat=10)):  0.207
    min(timeit.repeat(stmt4, setup, number=10000, repeat=10)):  0.208
    
So: better to store intermediate results in-place and use two steps (about 15% faster)

### Numpy: adding vector to all rows and all columns

    setup = "import numpy as np; vrow = np.random.rand(200); a = np.random.rand(200,200);"
    stmt1 = "vrow = vrow.reshape(1,200); vcol = vrow.reshape(200,1); a += vrow; a += vcol"
    stmt2 = "vcol = vrow.reshape(200,1); a += vrow; a += vcol"
    stmt3 = "a += vrow; a+= vrow.reshape(200,1)"
    stmt4 = "outer = np.add.outer(vrow,vrow); a += outer"
    
    min(timeit.repeat(stmt1, setup, number=10000, repeat = 10)):  0.327
    min(timeit.repeat(stmt2, setup, number=10000, repeat = 10)):  0.320
    min(timeit.repeat(stmt3, setup, number=10000, repeat = 10)):  0.325
    min(timeit.repeat(stmt4, setup, number=10000, repeat = 10)):  0.385
    
So: Better to use broadcasting (version 2) than explicit outer construction (about 20% faster). There is no need to reshape v to row format before broadcasting (will be taken as row vector automatically). It makes very little difference if column vector is first explicitly stored in intermediate variable or not


#### 